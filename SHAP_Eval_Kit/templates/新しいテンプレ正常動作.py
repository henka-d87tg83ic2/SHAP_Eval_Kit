# -*- coding: utf-8 -*-
"""template_main.ipynb のコピー

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nKeKu_UIpiICoTni3fVV5KH3BOhWDprA
"""

def analyze_feature_pairs(pairs, class_index=1):
    from sklearn.datasets import load_breast_cancer
    from sklearn.model_selection import train_test_split
    from sklearn.preprocessing import StandardScaler
    from sklearn.ensemble import RandomForestClassifier
    import shap, numpy as np, pandas as pd, json

    data = load_breast_cancer()
    X = pd.DataFrame(data.data, columns=data.feature_names)
    y = pd.Series(data.target)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    scaler = StandardScaler()
    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)
    X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X.columns)

    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train_scaled, y_train)
    explainer = shap.Explainer(model, X_train_scaled)

    for fx, fy in pairs:
        print(f"[処理中] {fx} vs {fy}")
        fx_idx, fy_idx = X.columns.get_loc(fx), X.columns.get_loc(fy)

        x_vals = np.linspace(X_test_scaled[fx].min(), X_test_scaled[fx].max(), 50)
        y_vals = np.linspace(X_test_scaled[fy].min(), X_test_scaled[fy].max(), 50)
        xx, yy = np.meshgrid(x_vals, y_vals)

        grid = pd.DataFrame({fx: xx.ravel(), fy: yy.ravel()})
        for col in X.columns:
            if col not in [fx, fy]:
                grid[col] = X_test_scaled[col].mean()
        grid = grid[X.columns]

        shap_vals_grid = explainer(grid).values[:, :, class_index]
        Z_shap = shap_vals_grid[:, fy_idx].reshape(xx.shape)

        neutral_mask = np.abs(Z_shap) < 0.02
        gradient_y, gradient_x = np.gradient(Z_shap)
        grad_mean = (np.mean(np.abs(gradient_x)), np.mean(np.abs(gradient_y)))
        direction = "X優勢" if grad_mean[0] > grad_mean[1] else "Y優勢"

        out_name = f"eval_{fx.replace(' ', '_')}_{fy.replace(' ', '_')}.json"
        result = {
            "特徴量ペア": f"{fx} vs {fy}",
            "中立点数": int(neutral_mask.sum()),
            "傾斜方向": direction
        }
        with open(out_name, "w", encoding="utf-8") as f:
            json.dump(result, f, indent=4, ensure_ascii=False)
        print(f"→ 評価結果保存: {out_name}")

# ===========================
# SHAP安全テンプレート構造
# ステップ1：SHAP値と入力データの保存
# ステップ2：補助マスク生成
# ステップ3：ファイルから安全に描画
# ===========================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import shap

# === ステップ1：SHAP出力保存 ===
def save_shap_output(explainer, X_scaled, class_index=1, save_prefix="shap_step1"):
    shap_values = explainer(X_scaled)  # ← 旧APIではなく新APIを使用
    shap_array_class1 = shap_values.values[:, :, class_index]  # (n_samples, n_features)
    np.save(f"{save_prefix}_shap_values.npy", shap_array_class1)
    X_scaled.to_csv(f"{save_prefix}_X_scaled.csv", index=False)
    print("[保存完了] SHAP値・スケーリング済データ")


# === ステップ2：中立領域マスク保存 ===
def save_neutral_mask(shap_file, feature_idx, threshold=0.02, save_prefix="shap_step1"):
    shap_vals = np.load(shap_file)
    neutral_mask = np.abs(shap_vals[:, feature_idx]) < threshold
    np.save(f"{save_prefix}_neutral_mask.npy", neutral_mask)
    print("[保存完了] 中立点マスク")

# === ステップ3：ファイルから描画 ===
def plot_from_saved(prefix, fx, fy, fx_idx, fy_idx, class_label="クラス1（悪性）"):
    shap_vals = np.load(f"{prefix}_shap_values.npy")
    X_df = pd.read_csv(f"{prefix}_X_scaled.csv")
    neutral_mask = np.load(f"{prefix}_neutral_mask.npy")

    plt.figure(figsize=(10, 8))
    plt.scatter(X_df[fx], X_df[fy], c=shap_vals[:, fy_idx], cmap="viridis", edgecolor="k", label="SHAP値")
    plt.scatter(X_df[fx][neutral_mask], X_df[fy][neutral_mask], c='yellow', label='SHAP ≈ 0', edgecolor='black')
    plt.colorbar(label="SHAP value")
    plt.xlabel(fx)
    plt.ylabel(fy)
    plt.title(f"SHAP可視化：{fx} vs {fy}\n（{class_label}）")
    plt.grid(True)
    plt.legend()
    plt.tight_layout()
    plt.show()
    print("[描画完了]")

# ===========================
# PDP・ICE 可視化テンプレート
# 安全にSHAP構造と組み合わせる補助分析
# ===========================

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn.inspection import PartialDependenceDisplay

# 必要なライブラリのインストール（Colab用）
!pip install scikit-learn

# === PDP実行関数 ===
def plot_pdp(model, X, features, feature_names=None, title="PDP - 部分依存プロット"):
    fig, ax = plt.subplots(figsize=(12, 6))
    PartialDependenceDisplay.from_estimator(model, X, features=features, grid_resolution=50, ax=ax)
    plt.suptitle(title)
    plt.tight_layout()
    plt.show()
    print("[PDP描画完了]")

# === ICE実行関数（全サンプルの軌跡） ===
def plot_ice(model, X, feature_index, feature_name="", title="ICE - 個別条件付き期待値"):
    grid = np.linspace(X.iloc[:, feature_index].min(), X.iloc[:, feature_index].max(), 50)
    ice_vals = []

    # データ型変換（Colab環境での互換性向上）
    X_values = X.values.astype(np.float32)

    for row in X_values:
        X_temp = np.tile(row, (50, 1))
        X_temp[:, feature_index] = grid
        preds = model.predict_proba(X_temp)[:, 1]  # 予測確率を取得
        ice_vals.append(preds)

    plt.figure(figsize=(10, 6))
    for curve in ice_vals:
        plt.plot(grid, curve, color='lightblue', alpha=0.4)

    plt.title(title + f"：{feature_name}")
    plt.xlabel(feature_name)
    plt.ylabel("予測確率")
    plt.grid(True)
    plt.tight_layout()
    plt.show()
    print("[ICE描画完了]")

# ===========================
# Colab用：SHAP構造評価テンプレート
# テンプレNo.46 の4分類を記録・出力
# ===========================

import json

def generate_shap_structure_report(result_dict, save_as="shap_structure_report.json"):
    """
    result_dict: dict 形式 例：
    {
        "中立領域": "偏りあり（右上）",
        "傾斜方向": "Y軸方向",
        "tick密度": "高密度（X=-0.3〜0.0）",
        "スイッチ帯": "明瞭（X≈-0.2, Y≈0.1）"
    }
    """
    with open(save_as, "w", encoding="utf-8") as f:
        json.dump(result_dict, f, indent=4, ensure_ascii=False)
    print(f"[レポート保存完了] {save_as}")

# === 使用例 ===
# report = {
#     "中立領域": "偏りあり（右上に集中）",
#     "傾斜方向": "Y軸方向（緩やか）",
#     "tick密度": "中程度（-0.4〜0.2に集中）",
#     "スイッチ帯": "あり（X≈-0.2で直角に折れ）"
# }
# generate_shap_structure_report(report, save_as="shap_template_eval.json")

# ===========================
# Colab用：SHAP + 予測確率の3D構造描画テンプレ
# ===========================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# === 3D描画関数 ===
def plot_shap_surface_3d(X_grid, fx, fy, Z_pred, title="3D構造：決定境界 or SHAP"):
    """
    X_grid: pd.DataFrame, fx/fyを含む特徴量データ（グリッド）
    fx, fy: str, X軸・Y軸となる特徴量名
    Z_pred: 2D array, Z軸（予測確率またはSHAP値）のメッシュ
    """
    fig = plt.figure(figsize=(10, 8))
    ax = fig.add_subplot(111, projection='3d')

    x_vals = np.unique(X_grid[fx].values)
    y_vals = np.unique(X_grid[fy].values)
    xx, yy = np.meshgrid(x_vals, y_vals)

    surf = ax.plot_surface(xx, yy, Z_pred, cmap='coolwarm', edgecolor='k', alpha=0.8)
    fig.colorbar(surf, ax=ax, shrink=0.5, aspect=10, label="Z value (予測 or SHAP)")

    ax.set_xlabel(fx)
    ax.set_ylabel(fy)
    ax.set_zlabel("Z値（予測確率またはSHAP）")
    ax.set_title(title)
    plt.tight_layout()
    plt.show()
    print("[3D構造描画完了]")

# ===========================
# SHAP 3D構造可視化：統合マスタースクリプト（Colab対応）
# ===========================

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# === 3D構造描画 ===
def plot_shap_surface_3d(X_grid, fx, fy, Z_pred, title="3D構造：予測 or SHAP"):
    x_vals = np.unique(X_grid[fx].values)
    y_vals = np.unique(X_grid[fy].values)
    xx, yy = np.meshgrid(x_vals, y_vals)

    fig = plt.figure(figsize=(10, 8))
    ax = fig.add_subplot(111, projection='3d')
    surf = ax.plot_surface(xx, yy, Z_pred, cmap='coolwarm', edgecolor='k', alpha=0.8)
    fig.colorbar(surf, ax=ax, shrink=0.5, aspect=10, label="Z value")

    ax.set_xlabel(fx)
    ax.set_ylabel(fy)
    ax.set_zlabel("Z値")
    ax.set_title(title)
    plt.tight_layout()
    plt.show()
    return xx, yy  # 傾斜・中立点描画用に返却

# === 傾斜方向（勾配）表示 ===
def plot_shap_gradient_field(Z_shap, xx, yy, title="SHAP傾斜方向（2D）"):
    dy, dx = np.gradient(Z_shap)
    plt.figure(figsize=(10, 8))
    plt.contourf(xx, yy, Z_shap, cmap='viridis', alpha=0.5)
    plt.quiver(xx, yy, dx, dy, color='black', angles='xy', scale_units='xy', scale=10, width=0.0025)
    plt.xlabel("X")
    plt.ylabel("Y")
    plt.title(title)
    plt.grid(True)
    plt.tight_layout()
    plt.show()

# === 中立点を重ねて描画 ===
def plot_shap_with_neutral_3d(xx, yy, Z_shap, threshold=0.02, title="SHAP + 中立点（3D表示）"):
    fig = plt.figure(figsize=(10, 8))
    ax = fig.add_subplot(111, projection='3d')
    surf = ax.plot_surface(xx, yy, Z_shap, cmap='coolwarm', alpha=0.7, edgecolor='gray')
    fig.colorbar(surf, ax=ax, shrink=0.5, aspect=10, label="SHAP value")

    neutral_mask = np.abs(Z_shap) < threshold
    x_neutral = xx[neutral_mask]
    y_neutral = yy[neutral_mask]
    z_neutral = Z_shap[neutral_mask]
    ax.scatter(x_neutral, y_neutral, z_neutral, c='yellow', s=20, label='SHAP ≈ 0', edgecolors='k')

    ax.set_xlabel("X")
    ax.set_ylabel("Y")
    ax.set_zlabel("SHAP")
    ax.set_title(title)
    ax.legend()
    plt.tight_layout()
    plt.show()

# ==========================
# SHAP特徴量ペア一括評価テンプレート（Colab対応）
# ==========================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import json
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_breast_cancer
import shap

# === 構造評価記録関数 ===
def record_structure_eval(pair_name, neutral_count, gradient_info, out_path):
    result = {
        "特徴量ペア": pair_name,
        "中立点数": int(neutral_count),
        "傾斜方向": gradient_info
    }
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(result, f, indent=4, ensure_ascii=False)

# === 一括評価関数 ===
def analyze_feature_pairs(pairs, class_index=1):
    data = load_breast_cancer()
    X = pd.DataFrame(data.data, columns=data.feature_names)
    y = pd.Series(data.target)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    scaler = StandardScaler()
    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)
    X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X.columns)
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train_scaled, y_train)

    explainer = shap.Explainer(model, X_train_scaled)
　　shap_vals = explainer(X_test_scaled).values[:, :, class_index]

    for fx, fy in pairs:
        print(f"[処理中] {fx} vs {fy}")
        fx_idx, fy_idx = X.columns.get_loc(fx), X.columns.get_loc(fy)

        x_vals = np.linspace(X_test_scaled[fx].min(), X_test_scaled[fx].max(), 50)
        y_vals = np.linspace(X_test_scaled[fy].min(), X_test_scaled[fy].max(), 50)
        xx, yy = np.meshgrid(x_vals, y_vals)

        grid = pd.DataFrame(np.c_[xx.ravel(), yy.ravel()], columns=[fx, fy])
        for col in X.columns:
            if col not in [fx, fy]:
                grid[col] = X_test_scaled[col].mean()
        grid = grid[X.columns]

        shap_vals_grid = explainer(grid).values[:, :, class_index]
        Z_shap = shap_vals_grid[:, fy_idx].reshape(xx.shape)

        neutral_mask = np.abs(Z_shap) < 0.02
        gradient_y, gradient_x = np.gradient(Z_shap)
        grad_mean = (np.mean(np.abs(gradient_x)), np.mean(np.abs(gradient_y)))
        direction = "X優勢" if grad_mean[0] > grad_mean[1] else "Y優勢"

        out_name = f"eval_{fx.replace(' ', '_')}_{fy.replace(' ', '_')}.json"
        record_structure_eval(f"{fx} vs {fy}", neutral_mask.sum(), direction, out_name)
        print(f"→ 評価結果保存: {out_name}")

"""# 過去から下

"""

# 必要なライブラリ
import shap
import pandas as pd
from sklearn.datasets import load_breast_cancer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# データ準備
data = load_breast_cancer()
X = pd.DataFrame(data.data, columns=data.feature_names)
y = pd.Series(data.target)

# 学習/検証用データに分割
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# スケーリング
scaler = StandardScaler()
X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)
X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X.columns)

# モデル学習
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train_scaled, y_train)

# SHAP Explainer 作成（TreeExplainer）
explainer = shap.Explainer(model, X_train_scaled)  # 新API

fy = "worst concave points"
fy_idx = X.columns.get_loc(fy)

save_shap_output(explainer, X_test_scaled, class_index=1, save_prefix="shap_step1")

save_neutral_mask(shap_file="shap_step1_shap_values.npy", feature_idx=fy_idx, threshold=0.02, save_prefix="shap_step1")

fx = "mean concave points"
fy = "worst concave points"
fx_idx = X.columns.get_loc(fx)
fy_idx = X.columns.get_loc(fy)

plot_from_saved(prefix="shap_step1", fx=fx, fy=fy, fx_idx=fx_idx, fy_idx=fy_idx, class_label="クラス1（悪性）")

report = {
    "中立領域": "左下に集中",
    "傾斜方向": "X軸優勢",
    "tick密度": "密（左側に集中）",
    "スイッチ帯": "X ≈ -0.4〜-0.2 にあり"
}
generate_shap_structure_report(report, save_as="shap_structure_report.json")

import numpy as np
import pandas as pd

# メッシュ生成
fx = "mean concave points"
fy = "worst concave points"
fx_idx, fy_idx = X.columns.get_loc(fx), X.columns.get_loc(fy)

x_vals = np.linspace(X_test_scaled[fx].min(), X_test_scaled[fx].max(), 50)
y_vals = np.linspace(X_test_scaled[fy].min(), X_test_scaled[fy].max(), 50)
xx, yy = np.meshgrid(x_vals, y_vals)

grid = pd.DataFrame({fx: xx.ravel(), fy: yy.ravel()})
for col in X.columns:
    if col not in [fx, fy]:
        grid[col] = X_test_scaled[col].mean()
grid = grid[X.columns]

shap_vals_grid = explainer(grid).values[:, :, 1]  # クラス1のSHAP値
Z_shap = shap_vals_grid[:, fy_idx].reshape(xx.shape)

plot_shap_surface_3d(X_grid=grid, fx=fx, fy=fy, Z_pred=Z_shap, title="SHAP 3D構造：mean concave vs worst concave")

plot_shap_gradient_field(Z_shap, xx, yy, title="SHAP傾斜方向（2Dベクトル場）")

from sklearn.inspection import PartialDependenceDisplay

# 特徴量インデックス取得
fx = "mean concave points"
fy = "worst concave points"
fx_idx = X.columns.get_loc(fx)
fy_idx = X.columns.get_loc(fy)

plot_pdp(model, X_test_scaled, features=[fx_idx, fy_idx],
         feature_names=[fx, fy], title="PDP - SHAP対象特徴量")

plot_ice(model, X_test_scaled, feature_index=fx_idx, feature_name=fx,
         title="ICE - mean concave points")

analyze_feature_pairs(
    pairs=[("mean concave points", "worst concave points")],
    class_index=1
)
